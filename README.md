# ğŸ“Š BanVic Data Engineering Case

Este projeto implementa um pipeline de dados com **Apache Airflow**, **PostgreSQL** e **Docker**, desenvolvido para o case da BanVic.  
O objetivo foi construir um processo de **extraÃ§Ã£o, transformaÃ§Ã£o e carga (ETL)** que orquestra dados de diferentes fontes (banco de origem e arquivo CSV) e carrega tudo em um Data Warehouse.  

---

## ğŸ› ï¸ Tecnologias utilizadas

- **Apache Airflow** para orquestraÃ§Ã£o  
- **PostgreSQL** como banco de origem e Data Warehouse  
- **Docker + Docker Compose** para infraestrutura  
- **Python (Pandas + SQLAlchemy + psycopg2)** para tratamento e carga dos dados  

---

## âš™ï¸ Como rodar o projeto

### 1. Clonar o repositÃ³rio

git clone https://github.com/pcastrodev/banvic-data-engineering-case.git
cd banvic-data-engineering-case

---

### 2. Subir os containers
docker compose up -d --build

---

### 3. Acessar o Airflow

URL: http://localhost:8080
UsuÃ¡rio: airflow
Senha: airflow

---

### 4. Executar o DAG

No Airflow, ative o DAG banvic_pipeline_dag e rode manualmente ou aguarde a execuÃ§Ã£o agendada (todos os dias Ã s 04h35).

## ğŸš€ Fluxo do pipeline

extract_from_source_db â†’ Extrai tabelas do Postgres de origem e salva em CSV
extract_from_csv_dataset â†’ Copia o dataset transacoes.csv para a partiÃ§Ã£o do dia
load_to_dw â†’ Carrega todos os CSVs no Data Warehouse (staging + tabelas finais)

---

## ğŸ“Š Estrutura no Data Warehouse

ApÃ³s rodar o pipeline, o DW recebe as tabelas:

public.source_agencias
public.source_clientes
public.source_colaboradores
public.source_colaborador_agencia
public.source_contas
public.source_propostas_credito
public.csv_transacoes

Exemplos de consultas:
-- Total de clientes
SELECT COUNT(*) FROM public.source_clientes;

-- Total de contas
SELECT COUNT(*) FROM public.source_contas;

-- Total de transaÃ§Ãµes
SELECT COUNT(*) FROM public.csv_transacoes;

---

## ğŸ‘¨â€ğŸ’» Autor
Desenvolvido por Pedro Castro (@pcastrodev
) como parte do case de Data Engineering da BanVic.
